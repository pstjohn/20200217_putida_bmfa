{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cobra.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cobra.io.load_json_model('reduced_iJN1463.json')\n",
    "reference_flux = pd.read_csv('reference_fluxes_GB032gfg.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = cobra.util.create_stoichiometric_matrix(model)\n",
    "v_star = reference_flux.values.flatten()\n",
    "\n",
    "N[:, v_star < 0] = -1 * N[:, v_star < 0]\n",
    "v_star = np.abs(v_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([545])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list(set(np.arange(N.shape[1])).difference(\n",
    "    np.unique(N, return_index=True, axis=1)[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td><strong>Name</strong></td>\n",
       "                <td>iJN1463</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Memory address</strong></td>\n",
       "                <td>0x07f06c4148090</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of metabolites</strong></td>\n",
       "                <td>665</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of reactions</strong></td>\n",
       "                <td>716</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Number of groups</strong></td>\n",
       "                <td>0</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Objective expression</strong></td>\n",
       "                <td>1.0*BIOMASS_KT2440_WT3 - 1.0*BIOMASS_KT2440_WT3_reverse_d86d5</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Compartments</strong></td>\n",
       "                <td>cytosol, periplasm, extracellular space</td>\n",
       "            </tr>\n",
       "          </table>"
      ],
      "text/plain": [
       "<Model iJN1463 at 0x7f06c4148090>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "met_labels = {m.id for m in model.metabolites}\n",
    "\n",
    "external_mets = {model.metabolites.index(m) for m in model.metabolites.query('e', 'compartment')}\n",
    "boundary_mets = {model.metabolites.index(met.id[:-2] + '_c') if (met.id[:-2] + '_c' in met_labels) else model.metabolites.index(met.id[:-2] + '_p') for met in model.metabolites.query('e', 'compartment')}\n",
    "measured_mets = {model.metabolites.index(model.metabolites.get_by_id(mid)) for mid\n",
    "                 in pd.read_csv('temp_data/measured_mets.csv').values.flatten()}\n",
    "biomass_mets = {model.metabolites.index(m) for m in model.reactions.BIOMASS_KT2440_WT3.reactants}\n",
    "\n",
    "protected_mets = external_mets | boundary_mets | measured_mets | biomass_mets\n",
    "\n",
    "# biomass_prods = {model.metabolites.index(m) for m in model.reactions.BIOMASS_KT2440_WT3.products}\n",
    "\n",
    "protected_rxns = {model.reactions.index(r) for r in model.exchanges + [model.reactions.BIOMASS_KT2440_WT3]}\n",
    "\n",
    "print(len(protected_mets))\n",
    "print(len(protected_rxns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = N.shape\n",
    "\n",
    "L = np.eye(m)\n",
    "R = np.eye(n)\n",
    "\n",
    "assert np.allclose(L @ N @ R @ v_star, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rinv = R\n",
    "\n",
    "assert np.allclose(L @ N @ R @ v_star, 0)\n",
    "assert np.allclose((Rinv @ R), np.eye(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.reactions.index(model.reactions.BIOMASS_KT2440_WT3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_single_stream_metabolite(met_to_remove, direction, L, N, R, Rinv):\n",
    "    N_sign = np.sign(N).astype(int)\n",
    "\n",
    "    rxn_to_remove = np.where(N_sign[met_to_remove] == direction)[0][0]\n",
    "    rxn_to_remove_origindex = (R @ np.arange(n))[rxn_to_remove].astype(int)\n",
    "    assert rxn_to_remove_origindex != 44, f\"Biomass removed with met {(np.arange(m) @ L)[met_to_remove]}\"\n",
    "\n",
    "    rxns_to_group = np.where(N_sign[met_to_remove] == -direction)[0]\n",
    "\n",
    "#     print('Reaction to remove:')\n",
    "#     print(np.where(N[:, rxn_to_remove]))\n",
    "#     print(N[np.where(N[:, rxn_to_remove])[0], rxn_to_remove])\n",
    "\n",
    "    assert len(rxns_to_group) == 1\n",
    "\n",
    "    for rxn in rxns_to_group:\n",
    "    \n",
    "#         print('Reaction to group (before):')    \n",
    "#         print(np.where(N[:, rxn]))\n",
    "#         print(N[np.where(N[:, rxn])[0], rxn])   \n",
    "    \n",
    "        fraction = -N[met_to_remove, rxn] / N[met_to_remove, rxn_to_remove]\n",
    "        N[:, rxn] += fraction * N[:, rxn_to_remove]\n",
    "        Rinv[:, rxn] += fraction * Rinv[:, rxn_to_remove]\n",
    "        \n",
    "#         print('Reaction to group (after):')        \n",
    "#         print(np.where(N[:, rxn]))\n",
    "#         print(N[np.where(N[:, rxn])[0], rxn])\n",
    "\n",
    "    N = np.delete(N, rxn_to_remove, 1)\n",
    "    Rinv = np.delete(Rinv, rxn_to_remove, 1)    \n",
    "    R = np.delete(R, rxn_to_remove, 0)\n",
    "\n",
    "    N = np.delete(N, met_to_remove, 0)\n",
    "    L = np.delete(L, met_to_remove, 1)\n",
    "\n",
    "    assert np.allclose(L @ N @ R @ v_star, 0)\n",
    "    assert np.allclose(Rinv @ R @ v_star, v_star)\n",
    "    return L, N, R, Rinv\n",
    "\n",
    "\n",
    "def get_duplicate_metabolites(N):\n",
    "    return np.array(list(set(np.arange(N.shape[0])).difference(\n",
    "        np.unique(N, return_index=True, axis=0)[1])))\n",
    "\n",
    "\n",
    "def get_duplicate_reactions(N):\n",
    "    return np.array(list(set(np.arange(N.shape[1])).difference(\n",
    "        np.unique(N, return_index=True, axis=1)[1])))\n",
    "\n",
    "\n",
    "# def remove_duplicate_reaction(rxn_to_remove, v_star, L, N, R, Rinv):\n",
    "#     rxn = [i for i, row in enumerate(N.T) if (row == N[:, rxn_to_remove]).all() and i != rxn_to_remove][0]\n",
    "\n",
    "#     rxn_to_remove_origindex = (R @ np.arange(n))[rxn_to_remove].astype(int)\n",
    "#     rxn_origindex = (R @ np.arange(n))[rxn].astype(int)\n",
    "\n",
    "#     N_test = np.delete(N, rxn_to_remove, 1)\n",
    "#     R_test = np.delete(R, rxn_to_remove, 0)\n",
    "\n",
    "#     R_test[rxn] *= (v_star[rxn_to_remove_origindex] + v_star[rxn_origindex]) / v_star[rxn_origindex]\n",
    "\n",
    "#     assert np.allclose(L @ N_test @ R_test @ Rsign @ v_star, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "356it [00:42, 20.07it/s, shape=(310, 361)]/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:24 \u001b[1;31mDeprecationWarning\u001b[0m: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:37 \u001b[1;31mDeprecationWarning\u001b[0m: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "360it [00:43, 18.45it/s, shape=(305, 361)]"
     ]
    }
   ],
   "source": [
    "# Protected metabolite mask\n",
    "mask = np.ones(m, dtype=bool)\n",
    "mask[list(protected_mets)] = False\n",
    "\n",
    "from tqdm import tqdm\n",
    "t = tqdm()\n",
    "\n",
    "while True:\n",
    "    \n",
    "    t.set_postfix(shape=f\"{N.shape}\")\n",
    "    t.update(1)\n",
    "    \n",
    "    N_sign = np.sign(N)\n",
    "    \n",
    "\n",
    "    Lmask = mask @ L.astype(bool)\n",
    "    \n",
    "    to_remove_source = np.where(\n",
    "        ((N_sign == 1).sum(1) == 1) & \n",
    "        ((N_sign == -1).sum(1) == 1) &         \n",
    "        Lmask)[0]\n",
    "    rxn_to_remove_source = pd.Series(\n",
    "        [(R @ np.arange(n))[np.where(N_sign[met_to_remove] == 1)[0][0]].astype(int)\n",
    "         for met_to_remove in to_remove_source])\n",
    "    to_remove_source = to_remove_source[~rxn_to_remove_source.isin(protected_rxns)]\n",
    "\n",
    "    if np.any(to_remove_source):\n",
    "        L, N, R, Rinv = remove_single_stream_metabolite(to_remove_source[0], 1, L, N, R, Rinv)  \n",
    "        continue\n",
    "        \n",
    "    to_remove_sink = np.where(\n",
    "        ((N_sign == 1).sum(1) == 1) &\n",
    "        ((N_sign == -1).sum(1) == 1) &\n",
    "        Lmask)[0]\n",
    "    rxn_to_remove_sink= pd.Series(\n",
    "        [(R @ np.arange(n))[np.where(N_sign[met_to_remove] == -1)[0][0]].astype(int)\n",
    "         for met_to_remove in to_remove_sink])\n",
    "    to_remove_sink = to_remove_sink[~rxn_to_remove_sink.isin(protected_rxns)]\n",
    "    \n",
    "    if np.any(to_remove_sink):\n",
    "        L, N, R, Rinv = remove_single_stream_metabolite(to_remove_sink[0], -1, L, N, R, Rinv)\n",
    "        continue \n",
    "        \n",
    "    duplicated_mets = get_duplicate_metabolites(N)\n",
    "    \n",
    "    if len(duplicated_mets) != 0:\n",
    "        # Remove protected mets\n",
    "        duplicated_mets = duplicated_mets[Lmask[duplicated_mets]]  \n",
    "    \n",
    "    if len(duplicated_mets) != 0:\n",
    "        N = np.delete(N, duplicated_mets[0], 0)\n",
    "        L = np.delete(L, duplicated_mets[0], 1)\n",
    "        assert np.allclose(L @ N @ R @ v_star, 0)\n",
    "        continue\n",
    "\n",
    "#     duplicated_rxns = get_duplicate_reactions(N)\n",
    "    \n",
    "#     if len(duplicated_rxns) != 0:\n",
    "#         N = np.delete(N, duplicated_rxns[0], 1)\n",
    "#         R = np.delete(R, duplicated_rxns[0], 0)\n",
    "#         Rinv = np.delete(Rinv, duplicated_rxns[0], 1)\n",
    "        \n",
    "#         assert np.allclose(L @ N @ R @ Rsign @ v_star, 0)\n",
    "#         continue        \n",
    "        \n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(305, 361)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Metabolite 10fthf_c at 0x7f06c4148150>,\n",
       " <Metabolite 13dpg_c at 0x7f06c4148410>,\n",
       " <Metabolite 2obut_c at 0x7f06c4148810>,\n",
       " <Metabolite 3mob_c at 0x7f06c4148750>,\n",
       " <Metabolite 34dhbz_c at 0x7f06c4148e90>,\n",
       " <Metabolite 34dhbz_e at 0x7f06c4148f90>,\n",
       " <Metabolite 25aics_c at 0x7f06c414cd90>,\n",
       " <Metabolite 3dhsk_c at 0x7f06c414cf10>,\n",
       " <Metabolite 26dap__M_c at 0x7f06c4154050>,\n",
       " <Metabolite 3pg_c at 0x7f06c4154190>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[model.metabolites[i] for i in (np.arange(m) @ L).astype(int)][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rxn_labels_original = pd.Series([r.id for r in model.reactions])\n",
    "rxn_labels_compressed = pd.Series([model.reactions[i].id for i in (R @ np.arange(n)).astype(int)])\n",
    "met_labels_compressed = pd.Series([model.metabolites[i].id for i in (np.arange(m) @ L).astype(int)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2AACLPGT160\n",
       "1        2AACLPGT180\n",
       "2      2AACLPPEAT160\n",
       "3      2AACLPPEAT180\n",
       "4         2DHGLCNtex\n",
       "           ...      \n",
       "356      EX_acon_T_e\n",
       "357    s7p_transport\n",
       "358         EX_s7p_e\n",
       "359           PHETA1\n",
       "360       CLPNS140pp\n",
       "Length: 361, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rxn_labels_compressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_matches():\n",
    "    for i, rxn_original in enumerate(model.reactions):\n",
    "        for rxn_index_compressed in np.where(np.sign(Rinv[i]))[0]:\n",
    "            yield (rxn_labels_compressed.loc[rxn_index_compressed], rxn_original.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(iter_matches(), columns=['compressed', 'original'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "361"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.compressed.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('compression_3.p', 'wb') as f:\n",
    "    pickle.dump({'L': L, 'N': N, 'R': R, 'Rinv': Rinv, 'm': m, 'n': n, 'matches': df, 'v_star': R @ v_star,\n",
    "                 'met_labels': met_labels_compressed, 'rxn_labels': rxn_labels_compressed}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "361it [01:00, 18.45it/s, shape=(305, 361)]"
     ]
    }
   ],
   "source": [
    "# N[:, rxn] += N[:, rxn_to_remove]\n",
    "# Rinv[:, rxn] += Rinv[:, rxn_to_remove]\n",
    "\n",
    "# N = np.delete(N, rxn_to_remove, 1)\n",
    "# Rinv = np.delete(Rinv, rxn_to_remove, 1)    \n",
    "# R = np.delete(R, rxn_to_remove, 0)\n",
    "\n",
    "# assert np.allclose(L @ N @ R @ Rsign @ v_star, 0)\n",
    "# assert np.allclose(Rinv @ R @ Rsign @ v_star, Rsign @ v_star)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
